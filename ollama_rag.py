import requests
import json
from typing import Dict, Optional
import warnings

# Transformer uyarƒ±larƒ±nƒ± bastƒ±r
warnings.filterwarnings("ignore", category=FutureWarning)
import os
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'


class OllamaRAGQA:
    """Ollama ile yerel LLM kullanarak RAG sistemi"""

    def __init__(self, retriever, model_name: str = "gemma3"):
        """
        Args:
            retriever: RAG retriever instance
            model_name: Ollama model adƒ± (gemma3, llama3.2, deepseek-r1 vb.)
        """
        self.retriever = retriever
        self.model_name = model_name
        self.ollama_url = "http://localhost:11434/api/generate"

    def check_ollama_status(self) -> bool:
        """Ollama'nƒ±n √ßalƒ±≈üƒ±p √ßalƒ±≈ümadƒ±ƒüƒ±nƒ± kontrol et"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=10)
            if response.status_code == 200:
                models_data = response.json()
                models = models_data.get('models', [])
                model_names = [model['name'] for model in models]
                print(f"üìã Mevcut modeller: {[name.split(':')[0] for name in model_names]}")

                # Kullanmak istediƒüimiz modelin var olup olmadƒ±ƒüƒ±nƒ± kontrol et
                current_model_exists = any(self.model_name in name for name in model_names)
                if not current_model_exists:
                    print(f"‚ö†Ô∏è Model '{self.model_name}' bulunamadƒ±!")
                    return False

                return True
            return False
        except requests.exceptions.ConnectionError:
            print("‚ùå Ollama sunucusuna baƒülanƒ±lamadƒ±. 'ollama serve' komutu √ßalƒ±≈ütƒ±rƒ±lmƒ±≈ü mƒ±?")
            return False
        except Exception as e:
            print(f"‚ùå Ollama baƒülantƒ± hatasƒ±: {e}")
            return False

    def generate_answer(self, question: str, context: str) -> str:

        if not self.check_ollama_status():
            return "Ollama √ßalƒ±≈ümƒ±yor. L√ºtfen 'ollama serve' komutunu √ßalƒ±≈ütƒ±rƒ±n."

        # Prompt uzunluƒüunu kontrol et - √ßok uzun olabilir
        if len(context) > 15000:
            context = context[:15000] + "..."
            print(f"Baƒülam √ßok uzun, kƒ±saltƒ±ldƒ±: {len(context)} karakter")

        # Sorunun dilini tespit et
        question_language = "Turkish" if any(turkish_word in question.lower() for turkish_word in ['nedir', 'nasƒ±l', 'neden', 'ne', 'kim', 'hangi']) else "English"
        
        # Yeni hibrit yakla≈üƒ±m: RAG bilgilerini kullanarak detaylƒ± ve samimi cevap
        prompt = f"""Sen yardƒ±mcƒ± ve bilgili bir yapay zeka asistanƒ±sƒ±n. Kullanƒ±cƒ±nƒ±n sorusunu a≈üaƒüƒ±daki bilgileri kullanarak cevaplayacaksƒ±n.

VERƒ∞ TABANI Bƒ∞LGƒ∞LERƒ∞:
{context}

KULLANICININ SORUSU: {question}

TALƒ∞MATLAR:
1. √ñnce verilen bilgileri analiz et
2. Bu bilgileri kullanarak soruya detaylƒ± bir cevap ver
3. Cevabƒ±nƒ± samimi ve yardƒ±msever bir tonla yaz
4. Eƒüer bilgi yoksa a√ßƒ±k√ßa belirt
5. Ek sorular olursa yardƒ±m etmeye hazƒ±r olduƒüunu s√∂yle
6. {question_language} dilinde cevap ver

L√ºtfen soruyu verilen bilgilere dayanarak yanƒ±tla:"""

        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.4,  # Orta seviye yaratƒ±cƒ±lƒ±k
                    "top_p": 0.9,
                    "max_tokens": 600  # Daha uzun cevaplar i√ßin
                }
            }

            print(f"üîç Ollama API'ye istek g√∂nderiliyor...")
            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                return result.get('response', 'Cevap alƒ±namadƒ±.')
            else:
                error_detail = ""
                try:
                    error_detail = response.json().get("error", "")
                except:
                    error_detail = response.text[:200]

                print(f"‚ùå Ollama API hatasƒ±: {response.status_code} - {error_detail}")
                return f"Ollama hatasƒ±: HTTP {response.status_code} - {error_detail}"

        except requests.exceptions.Timeout:
            return "‚è∞ Ollama yanƒ±t s√ºresi a≈üƒ±ldƒ±. Model √ßok b√ºy√ºk olabilir."
        except Exception as e:
            print(f"‚ùå Ollama baƒülantƒ± hatasƒ±: {str(e)}")
            return f"Ollama baƒülantƒ± hatasƒ±: {str(e)}"

    def is_general_chat_question(self, question: str) -> bool:
        """Sorunun genel sohbet sorusu olup olmadƒ±ƒüƒ±nƒ± kontrol et"""
        general_chat_keywords = [
            'merhaba', 'selam', 'hello', 'hi', 'hey',
            'nasƒ±lsƒ±n', 'nasƒ±l gidiyor', 'how are you', 'how do you do',
            'kimsin', 'who are you', 'what are you', 'ne yapƒ±yorsun',
            'sen kimsin', 'sen nesin', 'yapay zeka', 'artificial intelligence',
            'bot musun', 'robot musun', 'ai misin', 'asistan mƒ±sƒ±n',
            'te≈üekk√ºr', 'thank you', 'thanks', 'saƒüol', 'merci',
            'ho≈ü√ßa kal', 'bye', 'goodbye', 'g√∂r√º≈ü√ºr√ºz', 'see you',
            'yardƒ±m et', 'help me', 'yardƒ±m', 'help', 'nasƒ±l yardƒ±m',
            'anlat', 'tell me about yourself', 'kendin hakkƒ±nda',
            'iyi misin', 'are you ok', 'how you doing'
        ]
        
        question_lower = question.lower()
        
        # Spesifik bilgi sorularƒ±: "X nedir?" formatƒ± - RAG moduna gitsin
        if ('nedir' in question_lower or 'what is' in question_lower) and len(question.split()) > 1:
            # Sadece "nedir?" tek ba≈üƒ±na deƒüilse RAG moduna git
            if question_lower.strip() not in ['nedir?', 'what is?']:
                return False
        
        # Tam e≈üle≈üme kontrol√º (sadece √ßok genel sorular i√ßin)
        exact_matches = [
            'kimsin?', 'ne yapƒ±yorsun?', 'yardƒ±m?',
            'sen kimsin?', 'sen nesin?', 'sen ne yapƒ±yorsun?',
            'yapay zeka mƒ±sƒ±n?', 'bot musun?', 'ai misin?',
            'merhaba?', 'selam?', 'nedir?'
        ]
        
        if question_lower in exact_matches:
            return True
            
        return any(keyword in question_lower for keyword in general_chat_keywords)

    def generate_general_response(self, question: str) -> str:
        """Genel sohbet sorularƒ± i√ßin yapay zeka benzeri cevap √ºret"""
        if not self.check_ollama_status():
            return "Ollama √ßalƒ±≈ümƒ±yor. L√ºtfen 'ollama serve' komutunu √ßalƒ±≈ütƒ±rƒ±n."

        prompt = f"""Sen yardƒ±mcƒ± bir yapay zeka asistanƒ±sƒ±n. Kullanƒ±cƒ±nƒ±n sorusuna doƒüal ve samimi bir ≈üekilde cevap ver.

SORU: {question}

Kƒ±sa, samimi ve yardƒ±msever bir cevap ver. T√ºrk√ße cevap ver."""

        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,  # Daha yaratƒ±cƒ± yanƒ±tlar i√ßin
                    "top_p": 0.9,
                    "max_tokens": 150
                }
            }

            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result.get('response', 'Cevap alƒ±namadƒ±.')
            else:
                return "√úzg√ºn√ºm, ≈üu anda cevap veremiyorum."

        except Exception as e:
            return "Merhaba! Size nasƒ±l yardƒ±mcƒ± olabilirim?"

    def answer_question(self, question: str, top_k: int = 3, confidence_threshold: float = 0.2) -> Dict:
        # √ñnce genel sohbet sorusu mu kontrol et
        if self.is_general_chat_question(question):
            answer = self.generate_general_response(question)
            return {
                'question': question,
                'answer': answer,
                'context': "",
                'sources': [],
                'method': 'general_chat'
            }

        # RAG aramasƒ± yap
        search_results = self.retriever.search(question, top_k + 2)  # Daha fazla sonu√ß al, filtreleme sonrasƒ± i√ßin

        # Sonu√ß yoksa
        if not search_results:
            return {
                'question': question,
                'answer': "√úzg√ºn√ºm, bu soruyla ilgili bilgi bulamadƒ±m.",
                'context': "",
                'sources': [],
                'method': 'no_results'
            }

        # Sonu√ßlarƒ± √ße≈üitlendirmek i√ßin, aynƒ± i√ßerikleri filtrele
        filtered_results = []
        seen_texts = set()

        for result in search_results:
            # ƒ∞lk 50 karakter benzersiz mi kontrol et
            text_signature = result['text'][:50]
            if text_signature not in seen_texts:
                seen_texts.add(text_signature)
                filtered_results.append(result)
                if len(filtered_results) >= top_k:
                    break

        # Filtrelenmi≈ü sonu√ßlarƒ± kullan
        search_results = filtered_results[:top_k]

        # Baƒülam olu≈ütur
        context = self.retriever.get_context_for_query(question, top_k)

        # En y√ºksek g√ºven skoru
        top_confidence = search_results[0]['score'] if search_results else 0

        # G√ºven skoru d√º≈ü√ºkse
        low_confidence = top_confidence < confidence_threshold

        # Ollama ile cevap olu≈ütur
        if self.check_ollama_status():
            # G√ºven skoru d√º≈ü√ºkse uyarƒ± ekle
            if low_confidence:
                answer = self.generate_answer(question, context)
                answer = f"‚ö†Ô∏è G√ºven skoru d√º≈ü√ºk. Cevap doƒüru olmayabilir.\n\n{answer}"
                method = 'low_confidence'
            else:
                answer = self.generate_answer(question, context)
                method = 'ollama_generated'
        else:
            # Fallback: En iyi e≈üle≈üen d√∂k√ºmanƒ± kullan
            best_match = search_results[0]
            answer = f"üîç En ilgili bilgi: {best_match['text'][:300]}..."
            method = 'retrieval_only'

        return {
            'question': question,
            'answer': answer,
            'context': context,
            'sources': search_results,
            'confidence': top_confidence,
            'method': method
        }

    def interactive_qa(self):
        """Etkile≈üimli soru-cevap modu"""
        print("ü¶ô Ollama RAG Soru-Cevap Sistemi")
        print(f"Model: {self.model_name}")
        print("√áƒ±kmak i√ßin 'quit' yazƒ±n.")
        print("-" * 50)

        # Ollama durumunu kontrol et
        if not self.check_ollama_status():
            print("‚ö†Ô∏è  Ollama √ßalƒ±≈ümƒ±yor!")
            print("Kurulum i√ßin: https://ollama.ai")
            print("Ba≈ülatmak i√ßin: ollama serve")
            print("Model indirmek i√ßin: ollama deepseek-r1")
            print("\nYine de temel arama yapabilirsiniz...")
        else:
            print(f"‚úÖ Ollama aktif - Model: {self.model_name}")

        while True:
            question = input("\n‚ùì Sorunuz: ").strip()

            # Bo≈ü sorgu kontrol√º
            if not question:
                print("L√ºtfen bir soru yazƒ±n.")
                continue

            # √áƒ±kƒ±≈ü kontrol√º
            if question.lower() in ['quit', 'exit', '√ßƒ±k', '√ßƒ±kƒ±≈ü']:
                print("üëã Ho≈ü√ßa kalƒ±n!")
                break

            try:
                print("üîç Aranƒ±yor...")
                result = self.answer_question(question)

                print(f"\nüí¨ Cevap:")
                print(result['answer'])

                if result['sources']:
                    print(f"\nüìä G√ºven skoru: {result['confidence']:.3f}")
                    print(f"üìù Kaynak sayƒ±sƒ±: {len(result['sources'])}")
                    print(f"üîß Method: {result['method']}")

                    if len(result['sources']) > 0:
                        print(f"\nüìö Kaynaklar:")
                        for i, source in enumerate(result['sources'][:2]):
                            print(f"  {i+1}. {source['text'][:100]}... (skor: {source['score']:.3f})")
                elif result['method'] == 'general_chat':
                    print("üí¨ Genel sohbet modu")

            except KeyboardInterrupt:
                print("\n\nüëã Kullanƒ±cƒ± tarafƒ±ndan durduruldu!")
                break
            except Exception as e:
                print(f"\n‚ùå Hata olu≈ütu: {str(e)}")
                print(f"‚ùå Hata t√ºr√º: {type(e).__name__}")
                import traceback
                print(f"‚ùå Detaylƒ± hata:")
                traceback.print_exc()
                print("Tekrar deneyin veya 'quit' yazarak √ßƒ±kƒ±n.")


if __name__ == "__main__":
    from rag_system import RAGRetriever

    print("Ollama RAG sistemi ba≈ülatƒ±lƒ±yor...")

    retriever = RAGRetriever()

    try:
        retriever.load_from_files("faiss_index.bin", "documents.pkl")
        qa_system = OllamaRAGQA(retriever, model_name="gemma3")
        qa_system.interactive_qa()

    except FileNotFoundError:
        print("‚ùå Index dosyalarƒ± bulunamadƒ±. √ñnce data_processor.py √ßalƒ±≈ütƒ±rƒ±n.")
    except Exception as e:
        print(f"‚ùå Hata: {e}")
